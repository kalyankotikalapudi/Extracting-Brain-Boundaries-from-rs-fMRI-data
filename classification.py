# -*- coding: utf-8 -*-
"""classification

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1__aQWUID4IESkQ_WJFHo_I7s-Y6aTODC
"""

import os
import csv
from PIL import Image
import pickle
from numpy import asarray
import numpy as np
import cv2
import matplotlib.pyplot as plt

drive_path= os.getcwd()

img_dir = os.path.join(drive_path, "PatientData")
list_dir = [i for i in os.listdir(img_dir) if os.path.isdir(os.path.join(img_dir,i))]
image = []
label = []
for i in list_dir:
  for f1 in os.listdir(os.path.join(img_dir,i)):
    if("thresh" in f1 ):
      f2 = f1.split("_")
      csv_file = csv.reader(open(os.path.join(img_dir,i+str("_Labels.csv")), "r"), delimiter=",")
      next(csv_file,None)
      for row in csv_file:
        if(f2[1] == row[0]):
          if(int(row[1])>0):
            img = cv2.imread(os.path.join(img_dir,i,f1))
            img = cv2.resize(img, (256,256))
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            image.append(img)
            label.append(1)
          else:
            img = cv2.imread(os.path.join(img_dir,i,f1))
            img = cv2.resize(img, (256,256))
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            image.append(img)
            label.append(0)

X = np.array(image)
Y = np.array(label)

from sklearn.model_selection import train_test_split 
from keras.utils.np_utils import to_categorical

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=25)
Y_train = to_categorical(Y_train)
Y_test = to_categorical(Y_test)

from tensorflow.keras.applications import VGG16
from keras.models import Sequential,model_from_json
from keras.layers import Conv2D, Dense, Dropout, Flatten, Activation
from tensorflow.keras.metrics import BinaryAccuracy, Precision,Recall,AUC
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping
import tensorflow as tf
import keras.backend as K
import datetime
model_id='base_model'
no_epochs=100
early_stopping_patience = 50

base_model = VGG16(input_shape=(256,256, 3),include_top=False,weights="imagenet")
for layer in base_model.layers:
    layer.trainable=True

model=Sequential()
model.add(base_model)
model.add(Dropout(0.25))
model.add(Dense(8190))
model.add(Dropout(0.25))
model.add(Activation('relu'))
model.add(Dense(1020))
model.add(Dropout(0.25))
model.add(Activation('relu'))
model.add(Dense(130))
model.add(Dropout(0.25))
model.add(Activation('relu'))
model.add(Dense(20))
model.add(Dropout(0.25))
model.add(Activation('relu'))
model.add(Flatten())
model.add(Dense(2,activation='sigmoid'))


METRICS = [BinaryAccuracy(name='accuracy'),Precision(name='precision'),Recall(name='recall'),AUC(name='auc')]

reducelr_plateau = ReduceLROnPlateau(monitor = 'val_loss',patience = 5,verbose = 1,factor = 0.625, min_lr = 1e-10)

model_checkpoint = ModelCheckpoint(filepath=img_dir + '/' + model_id + '.h5',save_freq='epoch',period=1)

early_stopping = EarlyStopping(verbose=1, patience=early_stopping_patience)

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), loss='categorical_crossentropy',metrics=METRICS)

history=model.fit(X_train, Y_train,validation_data=(X_test, Y_test),verbose = 1,epochs = no_epochs,callbacks=[reducelr_plateau,model_checkpoint,early_stopping])

model.save(img_dir + "/model/"+model_id+str(datetime.datetime.now())+".h5")